{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enriched_text.entitites.text:Gap, labor|labour\n"
     ]
    }
   ],
   "source": [
    "from watson_developer_cloud import DiscoveryV1\n",
    "import pandas as pd\n",
    "import json \n",
    "import numpy as np\n",
    "\n",
    "# --- Authentication ----\n",
    "discovery = DiscoveryV1(\n",
    "    username=\"60dd891d-9f19-4fd2-bb8a-912add37f1b4\",\n",
    "    password=\"tN4F1bLcMzQH\",\n",
    "    version=\"2017-11-07\"\n",
    ")\n",
    "#--- Need to write a function to read seller ------\n",
    " #--- Write a generic query: if no results, use keyword -----\n",
    " \n",
    " \n",
    "qopts = {'query': 'enriched_text.entities.text:Gap, labor|labour', 'counts':'10'}\n",
    "my_query = discovery.query('system', 'news-en', qopts)\n",
    " #print(json.dumps(my_query, indent=2))\n",
    "\n",
    "input_seller = str('Gap')\n",
    "query_string = 'enriched_text.entities.text:' + input_seller + ', labor|labour'\n",
    "print(query_string)\n",
    "\n",
    "qopts2 = {'query': query_string, 'counts':'10'}\n",
    "     \n",
    "my_query2 = discovery.query('system', 'news-en', qopts2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['matching_results', 'results'])\n",
      "172605\n",
      "dict_keys(['id', 'result_metadata', 'author', 'enriched_title', 'crawl_date', 'url', 'host', 'text', 'main_image_url', 'country', 'source_type', 'language', 'publication_date', 'enriched_text', 'extracted_metadata', 'title', 'forum_title'])\n",
      "dict_keys(['entities', 'sentiment', 'semantic_roles', 'concepts', 'categories', 'relations', 'keywords'])\n",
      "dict_keys(['entities', 'sentiment', 'semantic_roles', 'concepts', 'categories', 'relations', 'keywords'])\n",
      "[0, 0, 0, 0, 0, 0.451173, -0.704429, 0, 0, 0]\n",
      "17\n",
      "[0, 0, 0, 0, 0, 0.451173, -0.704429, 0, 0, 0]\n",
      "[{'score': 0.045051, 'label': 'positive'}, {'score': -0.31166, 'label': 'negative'}, {'score': -0.31166, 'label': 'negative'}, {'score': 0.109221, 'label': 'positive'}, {'score': 0.552598, 'label': 'positive'}, {'score': -0.0681004, 'label': 'negative'}, {'score': -0.217517, 'label': 'negative'}, {'score': -0.267639, 'label': 'negative'}, {'score': 0.767466, 'label': 'positive'}, {'score': 0.737139, 'label': 'positive'}]\n",
      "[dict_keys(['entities', 'sentiment', 'semantic_roles', 'concepts', 'categories', 'relations', 'keywords']), dict_keys(['entities', 'sentiment', 'semantic_roles', 'concepts', 'categories', 'relations', 'keywords']), dict_keys(['entities', 'sentiment', 'semantic_roles', 'concepts', 'categories', 'relations', 'keywords']), dict_keys(['entities', 'sentiment', 'semantic_roles', 'concepts', 'categories', 'relations', 'keywords']), dict_keys(['entities', 'sentiment', 'semantic_roles', 'concepts', 'categories', 'relations', 'keywords']), dict_keys(['entities', 'sentiment', 'semantic_roles', 'concepts', 'categories', 'relations', 'keywords']), dict_keys(['entities', 'sentiment', 'semantic_roles', 'concepts', 'categories', 'relations', 'keywords']), dict_keys(['entities', 'sentiment', 'semantic_roles', 'concepts', 'categories', 'relations', 'keywords']), dict_keys(['entities', 'sentiment', 'semantic_roles', 'concepts', 'categories', 'relations', 'keywords']), dict_keys(['entities', 'sentiment', 'semantic_roles', 'concepts', 'categories', 'relations', 'keywords'])]\n",
      "['positive', 'negative', 'negative', 'positive', 'positive', 'negative', 'negative', 'negative', 'positive', 'positive']\n",
      "[21.070229, 19.57235, 19.402386, 19.19851, 18.363358, 17.905567, 17.381153, 17.153774, 15.426698, 15.327417]\n"
     ]
    }
   ],
   "source": [
    "print(my_query.keys())\n",
    "print(my_query[\"matching_results\"])\n",
    "print(my_query[\"results\"][0].keys())\n",
    "print(my_query[\"results\"][0]['enriched_title'].keys())\n",
    "print(my_query[\"results\"][0]['enriched_text'].keys())\n",
    "\n",
    "\n",
    "\n",
    "print([my_query[\"results\"][i]['enriched_title']['sentiment']['document']['score'] for i in range(10)])\n",
    "print(len(my_query[\"results\"][0]))\n",
    "print([my_query[\"results\"][i]['enriched_title']['sentiment']['document']['score'] for i in range(10)])\n",
    "print([my_query[\"results\"][i]['enriched_text']['sentiment']['document']for i in range(10)])\n",
    "print([my_query[\"results\"][i]['enriched_text'].keys() for i in range(10)])\n",
    "\n",
    "\n",
    "print([my_query[\"results\"][i]['enriched_text']['sentiment']['document']['label'] for i in range(10)])\n",
    "print([my_query[\"results\"][i]['result_metadata']['score'] for i in range(10)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'result_metadata', 'author', 'enriched_title', 'crawl_date', 'url', 'host', 'text', 'main_image_url', 'country', 'source_type', 'language', 'publication_date', 'enriched_text', 'extracted_metadata', 'title', 'forum_title'])\n",
      "['https://www.verite.org/working-with-women-worldwide/', 'https://www.theglobeandmail.com/report-on-business/international-business/asian-pacific-business/apple-vs-ivanka-trump-competing-ethics-collide-in-china/article37730807/', 'https://www.theglobeandmail.com/report-on-business/international-business/asian-pacific-business/apple-vs-ivanka-trump-competing-ethics-collide-in-china/article37730807/?cmpid=rss1']\n",
      "['Verit√©', 'Asia-Pacific Business - The Globe and Mail', 'The Globe and Mail - Asian-Pacific Business']\n"
     ]
    }
   ],
   "source": [
    "print(my_query[\"results\"][0].keys())\n",
    "urls = [my_query[\"results\"][i]['url'] for i in range(3)]\n",
    "earls = [my_query[\"results\"][i]['forum_title'] for i in range(3)]\n",
    "#earls = [my_query[\"results\"][i][\"result_metadata\"] for i in range(10)]\n",
    "\n",
    "print(urls)\n",
    "print(earls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([my_query[\"results\"][i][\"enriched_title\"]['sentiment']['document']['score'] for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = discovery.query(environment_id='system', collection_id='news-en', query='{query}', filter='{filter}', aggregation='{aggregation}', return_fields='{return_fields}' ...)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
